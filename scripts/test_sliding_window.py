#!/usr/bin/env python
import os
import sys

# ─── make project root importable ─────────────────────────────────────────────
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.abspath(os.path.join(SCRIPT_DIR, ".."))
if PROJECT_ROOT not in sys.path:
		sys.path.insert(0, PROJECT_ROOT)
# ─────────────────────────────────────────────────────────────────────────────

import time
import argparse
import logging
import numpy as np
import tensorflow as tf
from sklearn.metrics import accuracy_score, roc_curve, auc, roc_auc_score
import matplotlib.pyplot as plt
from pathlib import Path


from models.SlidingWindow import build_ptv3_jet_classifier, build_jedi_ptv3_hybrid
from models.PointTransformer_serialized import build_ptv3_serialized_jet_classifier

def resolve_test_dir(data_dir: str, dataset: str, run_id: str):
    data_dir = Path(data_dir)

    if dataset == "top":
        if (data_dir / "test").exists():
            return data_dir / "test"
        if (data_dir / run_id / "test").exists():
            return data_dir / run_id / "test"
        if (data_dir / "TopTagging" / run_id / "test").exists():
            return data_dir / "TopTagging" / run_id / "test"

    if dataset in ("QG", "qg"):
        if (data_dir / "test").exists():
            return data_dir / "test"
        if (data_dir / "QuarkGluon" / "test").exists():
            return data_dir / "QuarkGluon" / "test"

    raise FileNotFoundError(
        f"Could not resolve test directory for dataset={dataset}, data_dir={data_dir}"
    )

def profile_gpu_memory_during_inference(model: tf.keras.Model, input_data: np.ndarray) -> tuple[float, float]:
	logging.info("Starting GPU memory profiling")
	try:
		tf.config.experimental.reset_memory_stats('GPU:0')
	except Exception:
		logging.warning("GPU memory stats not available; skipping.")
		return 0.0, 0.0
	@tf.function
	def infer(x):
		return model(x, training=False)
	_ = infer(input_data[:1]); _ = infer(input_data)
	mem = tf.config.experimental.get_memory_info('GPU:0')
	curr = mem['current']/(1024**2)
	peak = mem['peak']/(1024**2)
	logging.info("GPU memory profiling done: current=%.1f MB, peak=%.1f MB", curr, peak)
	return curr, peak


def get_flops(model):
	logging.info("Starting FLOPs calculation")
	input_shape = model.input_shape
	concrete_shape = tuple([1] + list(input_shape[1:]))
	from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2_as_graph
	inp = tf.TensorSpec(concrete_shape, tf.float32)
	func = tf.function(model).get_concrete_function(inp)
	frozen_func, graph_def = convert_variables_to_constants_v2_as_graph(func)
	new_graph = tf.Graph()
	with new_graph.as_default():
		tf.compat.v1.import_graph_def(graph_def, name='')
		run_meta = tf.compat.v1.RunMetadata()
		opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()
		prof = tf.compat.v1.profiler.profile(graph=new_graph, run_meta=run_meta, cmd='op', options=opts)
		flops = prof.total_float_ops
	logging.info("FLOPs calculation done: %d FLOPs", flops)
	return flops

def _morton_interleave_bits_np(x: np.ndarray, y: np.ndarray, bits: int = 30) -> np.ndarray:
    x = x.astype(np.uint64)
    y = y.astype(np.uint64)
    z = np.zeros_like(x, dtype=np.uint64)
    for i in range(bits):
        z |= ((x >> i) & 1) << (2 * i)
        z |= ((y >> i) & 1) << (2 * i + 1)
    return z


def _morton_sort_indices_np(eta: np.ndarray, phi: np.ndarray, grid_size: float, bits: int = 30) -> np.ndarray:
    eta_min = np.min(eta, axis=1, keepdims=True)
    phi_min = np.min(phi, axis=1, keepdims=True)

    grid_eta = np.floor((eta - eta_min) / grid_size).astype(np.int64)
    grid_phi = np.floor((phi - phi_min) / grid_size).astype(np.int64)

    grid_eta = np.clip(grid_eta, 0, None).astype(np.uint64)
    grid_phi = np.clip(grid_phi, 0, None).astype(np.uint64)

    morton = _morton_interleave_bits_np(grid_eta, grid_phi, bits=bits)  # [B,N]
    return np.argsort(morton, axis=1)  # ascending

def apply_sorting(x, sort_by, grid_size = 0.05):
	logging.info("Starting sorting by '%s'", sort_by)
	if sort_by == "pt":
		key = x[:, :, 0]
	elif sort_by == "eta":
		key = x[:, :, 1]
	elif sort_by == "phi":
		key = x[:, :, 2]
	elif sort_by == "delta_R":
		key = np.sqrt(x[:, :, 1] ** 2 + x[:, :, 2] ** 2)
	elif sort_by == "kt":
		key = x[:, :, 0] * np.sqrt(x[:, :, 1] ** 2 + x[:, :, 2] ** 2)
	elif sort_by == "morton":
		eta = x[:, :, 1]
		phi = x[:, :, 2]
		idx = _morton_sort_indices_np(eta, phi, grid_size=grid_size)  # ascending
		return np.take_along_axis(x, idx[:, :, None], axis=1)
	elif sort_by == "random":
	    B, N, C = x.shape
	    idx = np.argsort(
	        np.random.rand(B, N), axis=1
	    )
	    return np.take_along_axis(x, idx[:, :, None], axis=1)
	else:
		return x
	idx = np.argsort(key, axis=1)[:, ::-1]
	sorted_x = np.take_along_axis(x, idx[:, :, None], axis=1)
	logging.info("Sorting done; data shape: %s", sorted_x.shape)
	return sorted_x


def load_test_data(dataset, data_dir, num_particles):
	logging.info("Loading test data for '%s'", dataset)
	if dataset == "hls4ml":
		x_test = np.load(os.path.join(data_dir, f"x_val_robust_{num_particles}const_ptetaphi.npy"))
		y_test = np.load(os.path.join(data_dir, f"y_val_robust_{num_particles}const_ptetaphi.npy"))
	elif dataset == "jetclass":
		x_test = np.load(os.path.join(data_dir, "JetClass/kinematics/test/features.npy"))
		y_test = np.load(os.path.join(data_dir, "JetClass/kinematics/test/labels.npy"))
		x_test = x_test.transpose(0, 2, 1)
	elif dataset == "top":
	    test_dir = resolve_test_dir(data_dir, "top", str(num_particles))
	    x_test = np.load(os.path.join(test_dir, "features.npy"))
	    y_test = np.load(os.path.join(test_dir, "labels.npy"))
	else:  #QG
	    test_dir = resolve_test_dir(data_dir, "QG", str(num_particles))  
	    x_test = np.load(os.path.join(test_dir, "features.npy"))
	    y_test = np.load(os.path.join(test_dir, "labels.npy"))
		
	logging.info("Loaded test arrays: x=%s, y=%s", x_test.shape, y_test.shape)
	return x_test, y_test


def select_preset(model_size):
	presets = {
			"small":  dict(enc_dims=[16], enc_layers=[1], enc_heads=[4], enc_strides=[2], enc_patch_sizes=[25], cpe_k=8, use_rpe=False),
			"small_2layer_no_downsamp": dict(enc_dims=[16, 16], enc_layers=[1, 1], enc_heads=[4, 4], enc_strides=[1, 1], enc_patch_sizes=[25, 25], cpe_k=8, use_rpe=False),
			"small_2layer_2_downsamp": dict(enc_dims=[16, 16], enc_layers=[1, 1], enc_heads=[4, 4], enc_strides=[2], enc_patch_sizes=[25, 25], cpe_k=8, use_rpe=False),
    		"matched": dict(enc_dims=[12, 16], enc_layers=[1, 1], enc_heads=[4, 4], enc_strides=[2], enc_patch_sizes=[25, 25], cpe_k=8, use_rpe=False),
    		"medium": dict(enc_dims=[12, 24, 32], enc_layers=[1, 1, 1], enc_heads=[4, 4, 4], enc_strides=[2, 2], enc_patch_sizes=[25, 25, 25], cpe_k=8, use_rpe=False),
    		"large":  dict(enc_dims=[16, 24, 32], enc_layers=[1, 1, 1], enc_heads=[4, 4, 4], enc_strides=[2, 2], enc_patch_sizes=[25, 25, 25], cpe_k=8, use_rpe=False),
    	}
	return presets[model_size]


def main():
	parser = argparse.ArgumentParser(description="Test SlidingWindow model")
	parser.add_argument("--dataset", choices=["hls4ml","top","jetclass","QG"], required=True)
	parser.add_argument("--data_dir", required=True)
	parser.add_argument("--save_dir", required=True)
	parser.add_argument("--sort_by", choices=["pt","eta","phi","delta_R","kt", "morton", "random"], default="pt")
	parser.add_argument("--batch_size", type=int, default=4096)
	parser.add_argument("--model_size", choices=["small", "small_2layer_no_downsamp", "small_2layer_2_downsamp", "matched", "medium", "large"], default="small")
	parser.add_argument("--enc_patch_sizes", type=int, nargs="+", default=None)
	parser.add_argument("--disable_pool", action="store_true", help="Disable GeometricPooling between stages")
	parser.add_argument("--use_rpe", action="store_true", help="Enable RPE regardless of preset")
	parser.add_argument("--grid_size", type=float, default=0.2, help="GeometricCPE grid size (coarser -> smaller grid)")
	parser.add_argument("--morton_grid_size", type=float, default=0.05, help="Grid size for morton sorting (separate from GeometricCPE grid_size)")
	parser.add_argument("--aggregation", choices=["mean", "max"], default="max", help="Aggregation method for final pooling")
	parser.add_argument("--weights", help="Path to weights .h5 file (defaults to save_dir/best.weights.h5)")
	parser.add_argument(
		"--use_serialized_model",
		action="store_true",
		help="Use the serialized PTv3 variant from PointTransformer_serialized",
	)
	parser.add_argument(
		"--serialize_by",
		choices=["morton", "pt", "kt"],
		default="morton",
		help="Serialization strategy for the serialized PTv3 model",
	)
	parser.add_argument("--enc_window_sizes", type=int,nargs="+", default=None, help="Sliding-window size per stage. 1 value to broadcast, or one per stage.")
	parser.add_argument("--ffn_activation", choices=["relu", "gelu", "swish", "silu", "tanh"], default="gelu", help="Activation function for feed-forward network (relu is fastest, gelu is default)")
	parser.add_argument("--use_jedi_hybrid", action="store_true", help="Use JEDI-PTv3 Hybrid (O(N) global interaction)")
	parser.add_argument("--disable_cpe", action="store_true", help="Disable CPE in JEDI hybrid")
	parser.add_argument("--cpe_type", choices=["original", "sinusoidal", "pairwise", "depthwise", "quantized"], default="original",
		help="Type of CPE to use: original (scatter/gather), sinusoidal (fastest), pairwise (k-NN), depthwise (1D conv), quantized (fixed grid)")
	parser.add_argument("--use_flash_attention", action="store_true")
	
	parser.add_argument("--patch_tokenizer_mode",
	    choices=["mean","max","flatten_dense","learned_pool"], default="mean")
	
	parser.add_argument("--message_proj", dest="message_proj", action="store_true", default=True)
	parser.add_argument("--no_message_proj", dest="message_proj", action="store_false")
	
	parser.add_argument("--message_gated", dest="message_gated", action="store_true", default=False)
	parser.add_argument("--no_message_gated", dest="message_gated", action="store_false")
	g = parser.add_mutually_exclusive_group()
	g.add_argument(
	    "--use_patch_messages",
	    dest="use_patch_messages",
	    action="store_true",
	    default=True,
	    help="Enable patch-message pathway (default: on)"
	)
	g.add_argument(
	    "--no_use_patch_messages",
	    dest="use_patch_messages",
	    action="store_false",
	    help="Disable patch-message pathway (patch tokenizer/proj/gate become irrelevant)"
	)
	args = parser.parse_args()

	# Logging
	os.makedirs(args.save_dir, exist_ok=True)
	log_path = os.path.join(args.save_dir, "test_ptv3.log")
	logging.basicConfig(filename=log_path, filemode="w", level=logging.INFO, format="%(asctime)s %(levelname)s %(message)s")
	cwd = os.getcwd()
	print(f"Running in directory: {cwd}")
	logging.info("Running in directory: %s", cwd)

	# Dataset defaults for num_particles and output_dim
	if args.dataset == "jetclass":
		num_particles = 150; output_dim = 10
	elif args.dataset == "top":
		num_particles = 200; output_dim = 1
	elif args.dataset == "QG":
		num_particles = 150; output_dim = 1
	else:
		num_particles = 150; output_dim = 5

	# Load data
	x_test, y_test = load_test_data(args.dataset, args.data_dir, num_particles)
	x_test = apply_sorting(x_test, args.sort_by, grid_size = args.morton_grid_size)

	# Build model from preset
	cfg = select_preset(args.model_size)
	enc_dims = cfg["enc_dims"]
	enc_layers = cfg["enc_layers"]
	enc_heads = cfg["enc_heads"]
	enc_strides = cfg["enc_strides"]
	enc_patch_sizes = cfg["enc_patch_sizes"] if args.enc_patch_sizes is None else args.enc_patch_sizes
	n_stages = len(enc_dims)

	enc_window_sizes = args.enc_window_sizes
	if enc_window_sizes is None:
	    enc_window_sizes = [20]  
	
	if len(enc_window_sizes) == 1 and n_stages > 1:
	    enc_window_sizes = enc_window_sizes * n_stages
	
	if len(enc_window_sizes) != n_stages:
	    raise ValueError(
	        f"enc_window_sizes has len {len(enc_window_sizes)} but expected {n_stages} (stages)"
	    )

	logging.info("Resolved enc_window_sizes: %s", enc_window_sizes)
	
	if len(enc_patch_sizes) == 1 and n_stages > 1:
		    enc_patch_sizes = enc_patch_sizes * n_stages  # broadcast single value
	if len(enc_patch_sizes) != n_stages:
		    raise ValueError(f"enc_patch_sizes has len {len(enc_patch_sizes)} but expected {n_stages} (stages)")
	cpe_k = cfg["cpe_k"]
	use_rpe = args.use_rpe or cfg["use_rpe"]

	# Build model: JEDI hybrid, serialized, or standard PTv3
	if args.use_jedi_hybrid:
		logging.info("Building JEDI-PTv3 Hybrid model (O(N) global interaction)")
		logging.info("CPE type: %s, CPE enabled: %s", args.cpe_type, not args.disable_cpe)
		model = build_jedi_ptv3_hybrid(
			num_particles=num_particles,
			output_dim=output_dim,
			enc_dims=enc_dims,
			enc_layers=enc_layers,
			enc_strides=enc_strides,
			cpe_k=cpe_k,
			grid_size=args.grid_size,
			use_pool=(not args.disable_pool),
			use_cpe=(not args.disable_cpe),
			cpe_type=args.cpe_type,
			dropout=0.0,
			aggregation=args.aggregation,
		)
	elif args.use_serialized_model:
		model = build_ptv3_serialized_jet_classifier(
			num_particles=num_particles,
			output_dim=output_dim,
			enc_dims=enc_dims,
			enc_layers=enc_layers,
			enc_heads=enc_heads,
			enc_patch_sizes=enc_patch_sizes,
			enc_strides=enc_strides,
			cpe_k=cpe_k,
			grid_size=args.grid_size,
			use_rpe=use_rpe,
			dropout=0.0,
			
			aggregation=args.aggregation,
			serialize_by=args.serialize_by,
			use_pool=(not args.disable_pool),
		)
	else:
		logging.info("Building PTv3 model (default fallback)")
		logging.info("CPE type: %s, CPE enabled: %s", args.cpe_type, not args.disable_cpe)
		model = build_ptv3_jet_classifier(
				num_particles=num_particles,
				output_dim=output_dim,
				enc_dims=enc_dims,
				enc_layers=enc_layers,
				enc_strides=enc_strides,
				enc_heads=enc_heads,
				enc_patch_sizes=enc_patch_sizes,
				enc_window_sizes=enc_window_sizes,
				use_rpe=use_rpe,
				cpe_k=cpe_k,
				grid_size=args.grid_size,
				use_pool=(not args.disable_pool),
				use_cpe=(not args.disable_cpe),
				dropout=0.0,
				aggregation=args.aggregation,
				ffn_activation=args.ffn_activation,
				use_patch_messages=args.use_patch_messages,
			    patch_tokenizer_mode=args.patch_tokenizer_mode,
			    message_proj=args.message_proj,
			    message_gated=args.message_gated,
			    use_flash_attention=args.use_flash_attention
			)
	model.summary(print_fn=lambda s: logging.info(s))
	logging.info("Preset: %s", args.model_size)
	logging.info("Hyperparams: dims=%s layers=%s heads=%s strides=%s patch=%s", enc_dims, enc_layers, enc_heads, enc_strides, enc_patch_sizes)

	# Load weights
	# Prefer pure weights file saved at the end of training; fallback to checkpoint
	default_weights = os.path.join(args.save_dir, "model.weights.h5")
	ckpt_weights = os.path.join(args.save_dir, "best.weights.h5")
	weights_path = args.weights or (default_weights if os.path.isfile(default_weights) else ckpt_weights)
	logging.info("Loading weights from %s", weights_path)
	try:
		# Try strict load first; if it fails, retry with skip_mismatch
		model.load_weights(weights_path)
		logging.info("Weights loaded via load_weights.")
	except Exception as e:
		logging.warning("load_weights failed: %s; retrying with skip_mismatch=True", e)
		try:
			model.load_weights(weights_path, skip_mismatch=True)
			logging.info("Weights loaded via load_weights with skip_mismatch=True (some variables may be skipped).")
		except Exception as e2:
			logging.warning("load_weights(skip_mismatch=True) failed: %s; trying load_model with custom_objects", e2)
			# If a full-model H5 was saved (e.g., by ModelCheckpoint without save_weights_only=True),
			# we need to pass custom objects to reconstruct the model.
			try:
				if args.use_serialized_model:
					from models.PointTransformer_serialized import (
						PTv3Block as SerializedPTv3Block,
						GeometricCPE as SerializedGeometricCPE,
						PatchedAttention as SerializedPatchedAttention,
						QuantizedRPE as SerializedQuantizedRPE,
						SerializedPooling2D,
						Serialization2D,
					)
					custom_objects = {
						"PTv3Block": SerializedPTv3Block,
						"GeometricCPE": SerializedGeometricCPE,
						"PatchedAttention": SerializedPatchedAttention,
						"QuantizedRPE": SerializedQuantizedRPE,
						"SerializedPooling2D": SerializedPooling2D,
						"Serialization2D": Serialization2D,
					}
				else:
					from models.SlidingWindow import (
						PTv3Block,
						GeometricCPE,
						PatchedAttention,
						QuantizedRPE,
						GeometricPooling,
					)
					custom_objects = {
						"PTv3Block": PTv3Block,
						"GeometricCPE": GeometricCPE,
						"PatchedAttention": PatchedAttention,
						"QuantizedRPE": QuantizedRPE,
						"GeometricPooling": GeometricPooling,
					}

				model = tf.keras.models.load_model(
					weights_path, custom_objects=custom_objects, compile=False
				)
				logging.info("Full model loaded via load_model with custom_objects.")
			except Exception as ee:
				logging.error("Failed to load model from %s: %s", weights_path, ee)
				raise

	# FLOPs and timing
	flops = get_flops(model)
	logging.info("FLOPs per inference: %d", flops)
	logging.info("MACs per inference: %d", flops // 2)

	logging.info("Warming up and timing inference (20 runs)")
	_ = model.predict(x_test[:args.batch_size], batch_size=args.batch_size)
	times = []
	for _ in range(20):
		t0 = time.perf_counter()
		_ = model.predict(x_test[:args.batch_size], batch_size=args.batch_size)
		times.append(time.perf_counter() - t0)
	avg_ns = np.mean(times) / args.batch_size * 1e9
	logging.info("Avg inference time/event: %.2f ns", avg_ns)

	curr_mb, peak_mb = profile_gpu_memory_during_inference(model, x_test[:args.batch_size])
	logging.info("GPU memory current: %.1f MB, peak: %.1f MB", curr_mb, peak_mb)

	# # Inference
	# logging.info("Running full prediction")
	# preds = model.predict(x_test, batch_size=args.batch_size)
	# logging.info("Predictions shape: %s", preds.shape)

	# # Metrics
	# logging.info("Computing metrics for dataset '%s'", args.dataset)
	# if args.dataset in ("top", "QG"):
	# 	acc = accuracy_score(y_test, (preds.ravel() > 0.5).astype(int))
	# 	auc_m = roc_auc_score(y_test, preds.ravel())
	# 	logging.info("Test Accuracy: %.4f, ROC AUC: %.4f", acc, auc_m)
	# else:
	# 	acc = accuracy_score(np.argmax(y_test, 1), np.argmax(preds, 1))
	# 	auc_m = roc_auc_score(y_test, preds, average="macro", multi_class="ovo")
	# 	logging.info("Test Accuracy: %.4f, ROC AUC: %.4f", acc, auc_m)

	# # ROC curves (optional)
	# if args.dataset == "hls4ml":
	# 	labels = ["q", "g", "W", "Z", "t"]
	# elif args.dataset == "top":
	# 	labels = ["qcd", "top"]
	# elif args.dataset == "QG":
	# 	labels = ["Gluon", "Quark"]
	# else:
	# 	labels = [f"label_{i}" for i in range(preds.shape[1])]

	# plt.figure(figsize=(6, 6))
	# one_over_fpr = {}
	# for i, lab in enumerate(labels):
	# 	if args.dataset in ("top", "QG"):
	# 		fpr, tpr, _ = roc_curve(y_test, preds.ravel())
	# 	else:
	# 		fpr, tpr, _ = roc_curve(y_test[:, i], preds[:, i])
	# 	roc_val = auc(fpr, tpr)
	# 	plt.plot(fpr, tpr, label=f"{lab} (AUC={roc_val:.2f})")
	# 	if np.max(tpr) >= 0.8:
	# 		fpr_t = np.interp(0.8, tpr, fpr)
	# 		one_over_fpr[lab] = 1.0 / fpr_t if fpr_t > 0 else np.nan
	# 		plt.plot(fpr_t, 0.8, "o")
	# plt.plot([0, 1], [0, 1], "k--")
	# plt.xlabel("FPR"); plt.ylabel("TPR"); plt.title("ROC curves")
	# plt.legend(loc="lower right"); plt.tight_layout()
	# plt.savefig(os.path.join(args.save_dir, "roc_curves_ptv3.png"))
	# plt.close()
	# for lab, val in one_over_fpr.items():
	# 	logging.info("1/FPR@0.8 for %s: %.3f", lab, val)
	# if one_over_fpr:
	# 	logging.info("Avg 1/FPR@0.8: %.3f", np.nanmean(list(one_over_fpr.values())))


if __name__ == "__main__":
	main()